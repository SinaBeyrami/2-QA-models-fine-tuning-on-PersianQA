{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Installing requirements**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install -q transformers accelerate evaluate tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T02:09:29.119753Z",
     "iopub.status.busy": "2025-07-20T02:09:29.119389Z",
     "iopub.status.idle": "2025-07-20T02:09:29.124520Z",
     "shell.execute_reply": "2025-07-20T02:09:29.123746Z",
     "shell.execute_reply.started": "2025-07-20T02:09:29.119725Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import json, torch\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForQuestionAnswering,\n",
    ")\n",
    "from evaluate import load as load_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using or overriding the postprocess**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T02:09:29.125566Z",
     "iopub.status.busy": "2025-07-20T02:09:29.125305Z",
     "iopub.status.idle": "2025-07-20T02:09:29.151311Z",
     "shell.execute_reply": "2025-07-20T02:09:29.150622Z",
     "shell.execute_reply.started": "2025-07-20T02:09:29.125539Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from transformers.utils.question_answering import postprocess_qa_predictions\n",
    "except Exception:\n",
    "    import torch\n",
    "    def postprocess_qa_predictions(\n",
    "        examples,\n",
    "        features,\n",
    "        all_start_logits,\n",
    "        all_end_logits,\n",
    "        n_best_size=20,\n",
    "        max_answer_length=30,\n",
    "        **kwargs\n",
    "    ):\n",
    "        ex           = examples[0]\n",
    "        offsets      = features[0][\"offset_mapping\"]\n",
    "        start_scores = all_start_logits[0]\n",
    "        end_scores   = all_end_logits[0]\n",
    "\n",
    "        start_idx = torch.argmax(start_scores).item()\n",
    "        end_idx   = torch.argmax(end_scores).item()\n",
    "\n",
    "        if end_idx < start_idx or end_idx - start_idx + 1 > max_answer_length:\n",
    "            return {ex[\"id\"]: \"\"}\n",
    "\n",
    "        start_char = offsets[start_idx][0]\n",
    "        end_char   = offsets[end_idx][1]\n",
    "        return {ex[\"id\"]: ex[\"context\"][start_char:end_char]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading the model and data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T02:09:29.152127Z",
     "iopub.status.busy": "2025-07-20T02:09:29.151952Z",
     "iopub.status.idle": "2025-07-20T02:09:29.176881Z",
     "shell.execute_reply": "2025-07-20T02:09:29.176339Z",
     "shell.execute_reply.started": "2025-07-20T02:09:29.152113Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on: cuda\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME   = \"pedramyazdipoor/persian_xlm_roberta_large\"\n",
    "TEST_FILE    = Path(\"/kaggle/input/test-set/pqa_test.json\")\n",
    "DEVICE       = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "MAX_LEN      = 512\n",
    "N_BEST       = 20\n",
    "MAX_ANS_LEN  = 30\n",
    "\n",
    "print(f\"Running on: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T02:09:29.178330Z",
     "iopub.status.busy": "2025-07-20T02:09:29.178097Z",
     "iopub.status.idle": "2025-07-20T02:09:32.811120Z",
     "shell.execute_reply": "2025-07-20T02:09:32.810404Z",
     "shell.execute_reply.started": "2025-07-20T02:09:29.178310Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(MODEL_NAME).to(DEVICE).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T02:09:32.812597Z",
     "iopub.status.busy": "2025-07-20T02:09:32.812347Z",
     "iopub.status.idle": "2025-07-20T02:09:32.824707Z",
     "shell.execute_reply": "2025-07-20T02:09:32.824205Z",
     "shell.execute_reply.started": "2025-07-20T02:09:32.812570Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with TEST_FILE.open(encoding=\"utf-8\") as f:\n",
    "    dataset = json.load(f)[\"data\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T02:09:32.825698Z",
     "iopub.status.busy": "2025-07-20T02:09:32.825421Z",
     "iopub.status.idle": "2025-07-20T02:10:44.137415Z",
     "shell.execute_reply": "2025-07-20T02:10:44.136487Z",
     "shell.execute_reply.started": "2025-07-20T02:09:32.825671Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9919cab3a0b43d884b737450e43b961",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2db9321f87841bea8a86eb9140a1183",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f51d4cd0f7e14194b6d0fb985fb9afc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Articles:   0%|          | 0/93 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds, refs = [], []\n",
    "metric = load_metric(\"squad_v2\")\n",
    "for art in tqdm(dataset, desc=\"Articles\"):\n",
    "    for para in art[\"paragraphs\"]:\n",
    "        ctx = para[\"context\"]\n",
    "        for qa in para[\"qas\"]:\n",
    "            qid, question = str(qa[\"id\"]), qa[\"question\"]\n",
    "\n",
    "            tok = tokenizer(\n",
    "                question, ctx,\n",
    "                return_offsets_mapping=True,\n",
    "                truncation=True,\n",
    "                max_length=MAX_LEN,\n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "\n",
    "\n",
    "            offset_mapping = tok.pop(\"offset_mapping\")\n",
    "            seq_ids = tok.sequence_ids(0)\n",
    "            context_mask = torch.tensor(\n",
    "                [sid == 1 for sid in seq_ids], dtype=torch.bool\n",
    "            )\n",
    "\n",
    "            tok = {k: v.to(DEVICE) for k, v in tok.items()}\n",
    "            context_mask = context_mask.to(DEVICE)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                out = model(**tok)\n",
    "\n",
    "            out.start_logits[0][~context_mask] = -1e9\n",
    "            out.end_logits[0][~context_mask]   = -1e9\n",
    "\n",
    "            pred_dict = postprocess_qa_predictions(\n",
    "                examples=[{\"id\": qid, \"context\": ctx, \"question\": question}],\n",
    "                features=[{\"offset_mapping\": offset_mapping[0]}],\n",
    "                all_start_logits=out.start_logits,\n",
    "                all_end_logits=out.end_logits,\n",
    "                n_best_size=N_BEST,\n",
    "                max_answer_length=MAX_ANS_LEN\n",
    "            )\n",
    "            pred_span = pred_dict[qid]\n",
    "\n",
    "            preds.append({\n",
    "                \"id\": qid,\n",
    "                \"prediction_text\": pred_span,\n",
    "                \"no_answer_probability\": 0.0\n",
    "            })\n",
    "            refs.append({\n",
    "                \"id\": qid,\n",
    "                \"answers\": {\n",
    "                    \"text\":         [a[\"text\"] for a in qa[\"answers\"]],\n",
    "                    \"answer_start\": [a[\"answer_start\"] for a in qa[\"answers\"]]\n",
    "                }\n",
    "            })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T02:10:44.138628Z",
     "iopub.status.busy": "2025-07-20T02:10:44.138367Z",
     "iopub.status.idle": "2025-07-20T02:10:44.390780Z",
     "shell.execute_reply": "2025-07-20T02:10:44.390058Z",
     "shell.execute_reply.started": "2025-07-20T02:10:44.138602Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exact Match: 51.08\n",
      "F1 Score   : 65.08\n"
     ]
    }
   ],
   "source": [
    "scores = metric.compute(predictions=preds, references=refs)\n",
    "print(f\"\\nExact Match: {scores['exact']:.2f}\")\n",
    "print(f\"F1 Score   : {scores['f1']:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7903459,
     "sourceId": 12520885,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
